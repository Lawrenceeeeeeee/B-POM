# Bilibili Public Opinion Monitor (B-POM)

## 项目基本实现思路

本项目针对B站开发一个舆情管理工具（后期可能扩展到其他平台），能够及时获取B站视频的评论信息，用文本分析的方法对评论进行分析，得出不同视频评论的舆情变化情况，同时对用户进行画像，并且将结果可视化展示。

## 项目结构

### 文件夹及文件说明：

- **`data/`**: 包含所有与数据相关的子目录和文件。

  - **`crawler/`**: 包含网页爬虫爬取的CSV数据文件。
  - **`word_frequencies/`**: 存储词频分析结果的表格。
  - **`frequency_plots/`**: 存储从词频数据生成的柱状图。
  - **`wordclouds/`**: 包含从文本数据生成的词云图。
  - **`resources/`**: 用于存储辅助文件，如停用词列表。
    - **`stopwords.txt`**: 包含需在文本分析中排除的停用词的文本文件。
- **`src/`**: 包含数据分析的Python脚本。

  - **`word_frequency_analyzer.py`**: 用于分析词频的Python类。
  - **`word_cloud_generator.py`**: 用于生成词云的Python类。
  - **`bvav.py`:**
  - **`embedding`**:用于词嵌入的Python类。
  - **`get_bilbil_videos.py`**:获取bilbil视频并且进行内容概括的Python类。
  - **`transcribe.py`**:
  - **`videos`**:
- **`web.py`**: 设置并运行 Gradio 界面的脚本。
- **`examples`**: 列出测试样例。
- **`client.py`**: 提供。

这个 Markdown 结构用中文详细说明了项目的每一个组成部分，提供了透明的概览，便于开发者、用户或贡献者理解和维护。

## 项目所用工具

1. 爬虫工具，主要目的是获取B站的一级评论信息，提供模型训练的训练数据
2. 文本分析工具，例如jieba库的使用，停用词库等的构建和使用
3. BERT模型的使用，主要用来进行评论的情绪分析和理智度的分析
4. Gradio的使用，借助Gradio库较低成本制作出了监测的Web界面
5. 自研工具，例如辅助打Tag的工具

## 项目流程

第一步，编写爬虫获取B站一级评论数据并且标准化

第二步，组内成员分工对获取的几千条数据进行两个维度的标记

第三步，对获得的数据进行基本的文本分析，例如词频统计

第四步，部署BERT，对标记后的数据进行学习

第五步，跟踪单一视频，生成舆情监控时序图，对用户进行画像

第六步，制作WebUI，将结果可视化呈现出来，降低使用成本

最后，计划增加Tag维度，进而可以对用户进行较好的聚类分析；将数据库引入，提供一套可以常态化管理和维护的舆情监控方案。

# 打Tag的统一标准

## Tag的分类

第一类：情绪分类指标（1-3）【1是消极、2是中立、3是积极】

    其中，这个指标只基于评论自己的情感色彩，与视频内容无关；提问帖讨论帖这些无明显情感倾向的均为中立。

第二类：观众满意指标（1-3）【1是不满、2是不在意、3是满意】

    其中，出现玩梗、刷沙发这类的评论，一律按照不在意考虑。

第三类：是否为提问贴（1，2）【1是不属于，2是属于】

第四类：是否为讨论帖（1，2）【1是不属于，2是属于】

第五类：是否为玩梗帖（1，2）【1是不属于，2是属于】

## 分类逻辑

第一类指标主要围绕评论区的情绪变化进行监控。

第二类指标主要围绕观众对该视频是否满意，便于了解观众偏好。

第三、四、五类指标主要为了更加清晰展示评论区的结构，将一些理性讨论的评论区纳入监控范围。

# 各大板块实现细节

## 评论相关度 correlation_score

评论相关度衡量的是评论与原视频内容的相关程度，旨在分析视频评论区的结构。

分析相关性最直接的思路就是进行word2vec，将文本转化成向量，通过余弦相似度来分析两条文本的相似程度。

考虑到视频内容的长度以及可能存在的长评论，BERT的embedding并不理想，很有可能会超出512 tokens的限制。因此，我们采用的是OpenAI的text-embedding-3-large模型，能接受更长的上下文，效果也很不错。

但b站视频通常不止涉及一个主题，通常会谈论很多个方面的内容。但评论大多数情况下最多只会设计一到两个主题，因此我们基于gpt-4-turbo来对视频内容进行分段概括，然后计算评论与每个部分的相关性，取最大值作为最终的相关性评分。

接下来就是获取视频内容。我们采取的方法是：通过b站api根据bv号来获取视频的音频信息，再借由whisper进行语音转写，从而提取视频文案（前提假设是视频类型是语言类视频，而非音乐类等无语音的视频）。由于视频的文案往往也比较长，我们采用gpt-4-turbo模型进行概括。

## 词频统计、词云和WebUI设计

word_freq部分:主要是文本分析中的词频分析部分。实现的功能是获得爬取的评论数据，按照数据类型修改代码，获得评论中的词频统计表。在运行过程中发现了停用词表在评论分析时存在一些遗漏，并且进行了补充。最后处于可视化的目的，将一个视频评论词频统计前10的评论画成柱状图。
wordcloud部分：主要是获取了上面词频统计表的数据，将其以词云图的形式展现
web部分：处于舆情分析实际应用便利性的需要，最终的结果采取了webui的可视化展现形式，采用了python的gradio库进行页面的搭建。其中嵌入了团队介绍，各个函数的调用开关，可视化图形输出。同时，还在页面的下端加入了特定的BV号对应的日志标记功能，监测者可以在了解了某个视频的舆情变化后记录笔记。

## Bert模型部分

考虑到选择tag数目和爬取评论条数，以及预训练模型的泛化能力，我们采用了人工打标和gpt辅助打标的方式相结合，这两部分的占比大致为6：4，并最终通过bert模型进行训练。

在人工打标方面，我们为了提升效率也进行了人工打标工具的开发，其具有进度自动保存和断点重连的能力。

在训练bert模型的方式选择上，我们先是尝试了多任务学习的方法，既一个推理层后接多个分类层，但发现因为选取tag的相关性不强，指标直接不能做到相互促进，因此为了各指标之间的推理不相互影响，我们选择了为每一个tag单独进行一个模型的训练。

基于多个模型的训练要求和模型的准确性，我们选取了bert-large-chinese的预训练模型，这个模型因为含有的参数量相较于bert—base-chinese更多，因而效果更好，但也更占用显存。基于此，我们在autodl平台上租赁了一台24g显存的4090的服务器进行模型的训练，首先，我们搭建了cuda和pytorch的环境用于加速模型训练，最终的效果大致为我们进行了2500条数据的训练，每一个模型的时长大概为3-4分钟，在验证集上的准确率也达到了75%-95%这个区间之内.


# Todo-list

- [X] 爬虫获取B站评论【只要一级评论】
- [X] 打Tag
- [X] 部署BERT，炼丹炉，启动！
- [ ] 【展示部分】跟踪单一视频，生成时序图
- [ ] 可以添加更多种类的Tag（机器人检测，理性程度)
- [X] 做WebUI
- [ ] PPT展示

目前进度：

已完成爬虫脚本，可以根据BV号获取视频

数据维度如下：

'oid','timestamp', 'rpid', 'uid', 'uname', 'content', 'likes', 'replies'

其中：

- oid：视频av号
- timestamp：时间戳
- rpid：评论id
- uid：用户id
- uname：用户名
- content：评论内容
- likes：点赞数
- replies：回复数（二级评论数)

统一了打Tag标准

构建了WebUI
